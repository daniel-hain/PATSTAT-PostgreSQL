---
title: "Patstat to Postgre SQL Database"
output: html_notebook
---

# Setup




```{r}
# Not sure if necessary... was an issue with a version conflict... try new version in the future again...
# devtools::install_version("RPostgres", version = "1.2.1", repos = "http://cran.us.r-project.org")

### general options
Sys.setenv(LANG = "en")
options("scipen" = 100, "digits" = 4) # override R's tendency to use scientific notation

### Clean workspace
rm(list=ls())
graphics.off()

### setWD (maybe needs installation of rstudioapi package)
# require(rstudioapi); setwd(dirname(rstudioapi::getActiveDocumentContext()$path)); getwd()

### Load packages (maybe need to be installed first)
# Standard
library(tidyverse) # General DS toolkit
library(magrittr) # For advanced piping
library(data.table) # for fast fread and other fast data transformations

# Databases
library(DBI) # GEneral R database interface
library(RPostgres) # PostgreSQL interface driver 
library(dbplyr) # for dplyr with databases
```

```{r}
# Outsourced in this script
source("000_define_functions.R")
```

# Preamble

## Define variables

First, we set up some variables, so the script runs on its own. 

* The first thing we have to do is to enter the information for connecting with the Postgre SQL database we want to populate with the PATSTAT data

```{r}
# Database access
var_dbname = "INSERT_YOUR_DB"
var_host = "INSERT_YOUR_HOST_ID"
var_port = 5432 # OR other
var_user = "INSERT_OUR_USER_NAME"
var_password = "INSERT_YOUR_PASSWORD"
```

* Next, we need to define the path (relative to our current working directory), where the downloaded PATSTAT files can be found.
* This files all have to be in the same folder.
* Therefore, unzip the `zip` files downloaded from PATSTAT twice until the results are `.csv` files (eg. `tls201_part01.csv`), and copy them all in the same folder.
* Attention: The `readr` package can also diectly read `zip` files, but it will truncate files >4gb (as all unzip options in R), therefore we have to manually do this.

```{r}
# PATSTAT folder
var_folder = "YORUDRIVE/YOURFOLDER"
```

## Connect to database

We now establish a connection to the database.

```{r}
# set up connection to existing PostgreSQL database, just plug in own details
con <- dbConnect(drv = RPostgres::Postgres(), 
                 dbname = var_dbname,
                 host = var_host, 
                 port = var_port,
                 user = var_user, 
                 password = var_password, 
                 sslmode = 'require'
                 )
```

```{r}
# Inspect DB:
con %>% dbListTables() %>% sort()
```



## Load adittional data: 

```{r}
table_names <- read_csv("data/PATSTAT_table_description.csv")
```

```{r}
file_list <- tibble(table_id = NA,
                    data = list.files(path = var_folder, pattern = "tls.*csv"),
                    path = paste(var_folder, data, sep = '/')) %>%
  mutate(data = gsub("\\.csv", "", .$data),
         table_id = gsub("\\_.*", "", .$data) )
```


```{r}
# Select or disselect certain rows
include_number <- 1:nrow(table_names) # Indicate by number the tables to include (all = 1:nrow(table.names) )
exclude_name <- c() # Indicate by name the tables to exclude, if you want to exclude some by name
```


```{r}
# subset the table
table_names_select <- table_names[include_number,] %>% filter(!(table_id %in% exclude_name) )
rm(include_number, exclude_name)
```





```{r}
data <- read_csv(
  file = paste0(file_list[1, 'path']),
  col_names = TRUE,
  na = c('', ' ', 'NA', 'XX', '9999-12-31', '9999'),
  quoted_na = TRUE,
  trim_ws = TRUE,
  guess_max = 1000000,
  progress = TRUE,
  skip_empty_rows = TRUE
)
```


```{r}
data2 <- read_csv(
  file = 'data/temp/tls201_part02.zip',
  col_names = TRUE,
  na = c("", "NA"),
  quoted_na = TRUE,
  trim_ws = FALSE,
  guess_max = 5000,
  progress = show_progress(),
  skip_empty_rows = TRUE
)
```


##############################################################################
# Load to PostgreSQ
##############################################################################

# Select or disselect certain rows
include_number <- 1:nrow(table.names) # Indicate by number the tables to include (all = 1:nrow(table.names) )
exclude_name <- c() # Indicate by name the tables to exclude, if you want to exclude some by name
# subset the table
table_names_select <- table_names[include_number,] %>% filter(!(table_id %in% exclude_name) )

# This loop imports all tables to the PostgreSQL database. You can instead also run the function sepperate for the tables
for(i in 1:nrow(table_names_select) ) {
  Patstat_to_PostgreSQL(files = file_list, 
                        db = con,
                        append = TRUE,
                        overwrite = FALSE,
                        tb_pat = table_names_select[i, "table_id"],
                        tb_own = table_names_select[i, "name"]
                        )
}

  # First check if everything is fine with input
  tb_pat %<>% pull()
  tb_own  %<>% pull()
  
  # Generate table name and subset index
  tb_name = paste(tb_pat, tb_own, sep = "_")
  index <- files %>%
    filter(table_id == tb_pat) %>%
    pull(data) 
    
  







